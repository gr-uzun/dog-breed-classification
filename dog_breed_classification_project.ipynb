{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVYZ3bLXVO39CAKITk67UN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gr-uzun/dog-breed-classification/blob/main/dog_breed_classification_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**120 Dog Breed Classification**\n",
        "\n",
        "Dataset: https://www.kaggle.com/datasets/amandam1/120-dog-breeds-breed-classification\n",
        "\n",
        "In this project, you will be trying to create a model to classify the dog breeds using the dataset\n",
        "given above.\n",
        "\n",
        "The aim of the project is to classify the dogâ€™s breed using the dataset which\n",
        "consists of 120 files.\n",
        "\n",
        "While creating the project, try to follow the instructions below and make\n",
        "sure that the project is unique."
      ],
      "metadata": {
        "id": "7JV07o8VSS7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attention**\n",
        "\n",
        "Before begin project, Download Kaggle Dataset directly into Google Drive (COLAB) by running **download_kaggle_dataset_into_google_drive.ipynb**"
      ],
      "metadata": {
        "id": "KIDvD7g-Q_Hw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Importing Required Libraries**\n",
        "\n",
        "- Import the required libraries for the project to the Colab environment.\n",
        "\n",
        "- Import Pandas, NumPy, Seaborn, Matplotlib, Sklearn and Tensorflow libraries for data\n",
        "analysis."
      ],
      "metadata": {
        "id": "h8qbyAGwS0XV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CIJRwXNNQi92"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "\n",
        "#from tensorflow import keras,math\n",
        "\n",
        "from keras import datasets, layers, models\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "import cv2\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Data Preprocessing**\n",
        "\n",
        "- In this section, prepare the data you have, for training the model.\n",
        "- Create a dataframe that includes pixel values of images and the labels\n",
        "- Use Label Encoding or One-Hot Encoding techniques to deal with categorical targets.\n",
        "- Split your dataset into X_train,X_test, X_val, y_train, y_test and y_val\n",
        "- Normalize the pixel values."
      ],
      "metadata": {
        "id": "wW_dS_o3UaRM"
      }
    }
  ]
}